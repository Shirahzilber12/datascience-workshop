{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Facial emotion\n",
    "\n",
    "\n",
    "\n",
    "Facial emotion recognition software is mostly used to allow a certain program to examine and process the expressions on a human’s face.\n",
    "\n",
    "This software acts like a human brain making it capable of recognizing emotions too.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Technical challenges\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Like any machine learning and deep learning algorithms, ER solutions require a lot of training data.\n",
    "\n",
    "\n",
    "\n",
    "This data must include photos from various angles, with various backgrounds, with people of different genders, ages, nationalities, races, etc.\n",
    "\n",
    "\n",
    "\n",
    "However, most public datasets aren’t sufficient. They aren’t diverse enough in terms of race and gender and contain limited sets of emotional expressions.\n",
    "\n",
    "\n",
    "\n",
    "There are some ways to overcome this issue:\n",
    "\n",
    "\n",
    "\n",
    " - Create your own dataset.\n",
    "\n",
    "   This is the most expensive and time-consuming way, but you’ll end\n",
    "\n",
    "   up with a dataset perfectly suited for your task\n",
    "\n",
    "   (recommended but almost impossible for individuals)\n",
    "\n",
    "\n",
    "\n",
    " - Combine several datasets. You can cross-check the performance of\n",
    "\n",
    "   your solution on several other datasets.\n",
    "\n",
    "\n",
    "\n",
    "Nowdays, ER is used for various purposes on a daily basis that almost no-one can't even notice.\n",
    "\n",
    "\n",
    "\n",
    "Investigations, job interviews and security are a small part of all possible application\n",
    "\n",
    "we can detect the emotions of a person with just the use of this technology\n",
    "\n",
    "\n",
    "The more accurate and reliable the ER process is, the more we can use it for human resources and security on a regular basis.\n",
    "\n",
    "And will make a great contribution to humanity.\n",
    "\n",
    "\n",
    "We choose the topic out of an understanding of its importance, the technological challenge, and the great potential inherent in it.\n",
    "\n",
    "\n",
    "With pleasure,\n",
    "Haim Kalfon and Shira Constantiner\n",
    "Computer Science Students at Open University of Israel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What will be the workflow of this project?\n",
    "\n",
    "* First, We will explore the dataset and attempt to make EDA of data (Done)\n",
    "* Later preprocess the data as requried, this includes image augumentations, scaling and what else need? (Done)\n",
    "* Try to build a basic vanilla CNN, and try to predict species as a binary classification problem\n",
    "* Later try to make predictions with transfer learning using ResNet50 and imagenet weights (In future)\n",
    "* Finally compare the results on vanilla CNN and ResNet50 with sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain - dataset of images\n",
    "\n",
    "##### CK+48\n",
    "\n",
    "```\n",
    "The data consists of 48x48 pixel grayscale images of faces.\n",
    "The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image.\n",
    "\n",
    "The dataset is separated into seven classes wich are (0=Anger, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
    "The dataset consists of 783 images for training and 198 images for testing (we update class labels to match 'emotions' then we ran a script to split images into train and test datasets)\n",
    "```\n",
    "\n",
    "To downloaded CK+48 dataset [Click here](https://www.kaggle.com/datasets/shawon10/ckplus/download)\n",
    "\n",
    "##### FER13\n",
    "\n",
    "```\n",
    "The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image.\n",
    "\n",
    "The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Anger, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples.\n",
    "```\n",
    "\n",
    "To downloaded FER13 dataset [Click here](https://www.kaggle.com/datasets/msambare/fer2013) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to start our coding journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# Labels\n",
    "emotions = [\"anger\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "# Datasets directories\n",
    "FER13_PATH = './FER13'\n",
    "CK48_PATH = './CK+48'\n",
    "#FERG_PATH = './FERG_DB_256'\n",
    "\n",
    "class Params:\n",
    "\t# Visualization\n",
    "\tFIG_SIZE = (10, 10)\n",
    "\tPIC_SIZE = 50\n",
    "\n",
    "\t# Images parameters for data augmentation and loading data\n",
    "\tGRAY_SCALE = False\n",
    "\tROTATION_FACTOR = .1\n",
    "\tZOOM_FACTOR = .1\n",
    "\tCONTRAST_FACTOR = .1\n",
    "\n",
    "\t# Dataset parameters\n",
    "\tSEED = 4242\n",
    "\tIMAGE_HEIGHT = 48\n",
    "\tIMAGE_WIDTH = 48\n",
    "\tVALIDATION_SPLIT = 0.2\n",
    "\n",
    "\t# Neural Network hyperparameters\n",
    "\tDROPOUT_RATE = 0.2\n",
    "\tPATIENCE = 5\n",
    "\tNUM_CLASSES = 7\n",
    "\tEPOCHS = 30\n",
    "\tBATCH_SIZE = 64\n",
    "\tBUFFER_SIZE = 128\n",
    "\n",
    "\tCHANNELS = 1 if GRAY_SCALE else 3\n",
    "\tSHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)\n",
    "\n",
    "Params = Params()\n",
    "\n",
    "def update_channel_and_shapes(params):\n",
    "\tparams.CHANNELS = 1 if params.GRAY_SCALE else 3\n",
    "\tparams.SHAPE = (params.IMAGE_HEIGHT, params.IMAGE_WIDTH, params.CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write some utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def _debug(str):\n",
    "\tif DEBUG: print(f'[DEBUG] {str}')\n",
    "\n",
    "def _reshape_image(img):\n",
    "\t'''\n",
    "\t\tAssume the image has 3 channels the reshape it to 1 channel \n",
    "\t'''\n",
    "\tgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\tgray = cv.resize(gray, (Params.IMAGE_HEIGHT, Params.IMAGE_WIDTH))\n",
    "\t\n",
    "\treshaped = gray.reshape(Params.SHAPE)\n",
    "\t_debug(reshaped.shape)\n",
    "\treturn reshaped\n",
    "\n",
    "def _plot_image(dataset, rescale=False, contrast = False):\n",
    "\timage = None\n",
    "\tfor images, _ in dataset.take(1):\n",
    "\t\timage = images[0]\n",
    "\t\n",
    "\tif image == None: return\n",
    "\timage = image.numpy()\n",
    "\t# if not GRAY_SCALE: image = _reshape_image(image)\n",
    "\n",
    "\t_debug(f'Rescale is set to {rescale}')\n",
    "\tcmap = None\n",
    "\n",
    "\tplt.figure()\n",
    "\tif rescale: \n",
    "\t\timage = image/255.\n",
    "\t\tif contrast: image = 1 - image\n",
    "\t\tcmap = plt.cm.binary\n",
    "\t\tplt.imshow(image, cmap=cmap)\n",
    "\telse: plt.imshow(image.astype('uint8'))\n",
    "\t\n",
    "\tplt.title(f'Values are in range({np.min(image)}, {np.max(image)})')\n",
    "\tplt.colorbar()\n",
    "\tplt.grid(False)\n",
    "\tplt.show()\n",
    "\n",
    "def visualize_dataset(dataset):\n",
    "\t'''\n",
    "\t\tSummary: Helper to visualize our dataset images\n",
    "\n",
    "\t\tArguments: Accept a Dataset \n",
    "\n",
    "\t\tRetruns: None, plot images\n",
    "\t'''\n",
    "\n",
    "\tplt.figure(figsize=Params.FIG_SIZE)\n",
    "\tfor images, labels in dataset.take(1):\n",
    "\t\tfor i in range(9):\n",
    "\t\t\tax = plt.subplot(3, 3, i + 1)\n",
    "\t\t\timage = images[i].numpy()\n",
    "\t\t\t_debug(f'Image shape is: {image.shape}')\n",
    "\t\t\tplt.imshow(image.astype(\"uint8\"))\n",
    "\t\t\tplt.title(dataset.class_names[labels[i]])\n",
    "\t\t\t\n",
    "\tplt.show()\n",
    "\n",
    "def plot_image_values_range(dataset):\n",
    "\t_plot_image(dataset)\n",
    "\n",
    "def plot_rescaled_image(dataset):\n",
    "\t_plot_image(dataset, True)\n",
    "\n",
    "def plot_bar_chart(dataset, validation_dataset, name):\n",
    "\t'''\n",
    "\t\tSummary: Helper to visualize our train and validation dataset images distibution by classes \n",
    "\n",
    "\t\tArguments: Accept a train Dataset, validation Dataset, and a name as title\n",
    "\n",
    "\t\tRetruns: None, plot bar diagram\n",
    "\t'''\n",
    "\n",
    "\tx = np.arange(len(emotions))\n",
    "\twidth = .35\n",
    "\n",
    "\tfig, ax = plt.subplots()\n",
    "\n",
    "\tfor _, labels in dataset.take(1):\n",
    "\t\tper_classes = np.bincount(labels)\n",
    "\t\ttrain_bar = ax.bar(x - width/2, per_classes, tick_label = emotions, width = width, label='Train')\n",
    "\t\tax.bar_label(train_bar, padding=3)\n",
    "\n",
    "\tfor _, labels_val in validation_dataset.take(1):\n",
    "\t\tper_classes_val =  np.bincount(labels_val)\n",
    "\t\tvalidation_bar = ax.bar(x + width/2, per_classes_val, tick_label = emotions,width = width, label='Validation')\n",
    "\t\tax.bar_label(validation_bar, padding=3)\n",
    "\n",
    "\tax.set_ylabel('# Images')\n",
    "\tax.set_title(f'Number of Images by Class for {name} dataset')\n",
    "\tax.set_xlabel('Class Name')\n",
    "\tax.legend()\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "def plot_accuracy_and_loss(history, name):\n",
    "\n",
    "\t'''\n",
    "\t\tSummary: Helper to visualize the diagram of  train and validation dataset images accuracy and loss \n",
    "\t\t\tafter model training\n",
    "\n",
    "\t\tArguments: Accept a history (from model.fit()) and the name of our Dataset\n",
    "\n",
    "\t\tRetruns: None, plot accuracy and loss graph diagram\n",
    "\t'''\n",
    "\t\n",
    "\tacc = history.history['accuracy']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\tloss = history.history['loss']\n",
    "\tval_loss = history.history['val_loss']\n",
    "\n",
    "\tepochs_range = range(len(acc))\t\n",
    "\tplt.figure(figsize=(15, 15))\n",
    "\t\n",
    "\tplt.subplot(2, 2, 1)\n",
    "\tplt.plot(epochs_range, loss, label='Training Loss')\n",
    "\tplt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "\tplt.legend(loc='upper right')\n",
    "\tplt.title(f'Training and Validation Loss for {name} dataset')\n",
    "\tplt.grid(True)\n",
    "\tplt.axis('on')\n",
    "\n",
    "\tplt.subplot(2, 2, 2)\n",
    "\tplt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "\tplt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "\tplt.legend(loc='lower right')\n",
    "\tplt.title(f'Training and Validation Accuracy for {name} dataset')\n",
    "\tplt.grid(True)\n",
    "\tplt.axis('on')\n",
    "\t\n",
    "\tplt.show()\n",
    "\n",
    "def _plot_confusion_matrix(labels, predictions):\n",
    "\n",
    "\tdef map_labels_to_index(arr):\n",
    "\t\treturn np.vectorize(lambda x: emotions[x])(arr)\n",
    "\n",
    "\tlabels = map_labels_to_index(labels)\n",
    "\tpredictions = map_labels_to_index(predictions)\n",
    "\n",
    "\t_debug(f'Display 10 labels: {labels[:10]}')\n",
    "\t_debug(f'Display 10 predictions: {predictions[:10]}')\n",
    "\n",
    "\tcm = confusion_matrix(labels, predictions, emotions)\n",
    "\t\n",
    "\tdf_cm = pd.DataFrame(cm, index = emotions, columns = emotions)\n",
    "\tplt.figure(figsize=Params.FIG_SIZE)\n",
    "\tsns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\tplt.title('Confusion matrix')\n",
    "\tplt.ylabel('Actual label')\n",
    "\tplt.xlabel('Predicted label')\t\n",
    "\tplt.show()\n",
    "\n",
    "\ttransposed = cm.transpose()\n",
    "\twrongs, rights = 0, 0\n",
    "\tfor i, e in enumerate(emotions):\n",
    "\t\tright = cm[i][i]\n",
    "\t\twrong = np.sum(transposed[i]) - right\n",
    "\n",
    "\t\tprint(f'{e.capitalize()}\\n\\tRight Classified (True Negatives): {right}\\n\\t Total Missed Classification: {wrong}')\n",
    "\t\trights += right\n",
    "\t\twrongs += wrong\n",
    "\n",
    "\n",
    "\tratio = rights/ np.sum(cm)\n",
    "\t_debug(ratio)\n",
    "\tpercentage = '{0:.2f}'.format(ratio*100)\n",
    "\tprint(f'\\nPercentage of right classifications is {percentage}%\"')\n",
    "\n",
    "def plot_confusion_matrix_for_test_dataset(dataset, predictions):\n",
    "\t# fetch real labels from test dataset (assuming its small enough to iterate over the entire dataset)\n",
    "\tlabels = None\n",
    "\tfor _, lbls in dataset.as_numpy_iterator():\n",
    "\t\tif labels is None: labels = lbls.flatten()\n",
    "\t\telse: labels = np.concatenate([labels, lbls.flatten()])\n",
    "\n",
    "\t_plot_confusion_matrix(labels, predictions)\n",
    "\n",
    "def plot_confusion_matrix_for_train_dataset(dataset, predictions):\n",
    "\n",
    "\t# fetch real labels from dataset batch\n",
    "\tlabels = None\n",
    "\tfor _, lbls in dataset.take(1):\n",
    "\t\tif labels is None: labels = lbls\n",
    "\t\telse: labels = np.concatenate([labels, lbls])\n",
    "\n",
    "\t_plot_confusion_matrix(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write utils functions to help us dealing with creating our dataset\n",
    "\n",
    "Because our dataset is a set of images we don't want to load it all in RAM that why we make use of keras function image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "def _color_mode():\n",
    "\treturn 'grayscale' if Params.GRAY_SCALE else 'rgb'\n",
    "\n",
    "def _preprocessing(dataset):\n",
    "\tds = dataset.cache()\n",
    "\tds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\treturn ds\n",
    "\n",
    "def _train_from_dir(path, subset):\n",
    "\tds = image_dataset_from_directory(path,\n",
    "\t\tvalidation_split=Params.VALIDATION_SPLIT,\n",
    "\t\tseed=Params.SEED,\n",
    "\t\tsubset=subset,\n",
    "\t\tshuffle=True,\n",
    "\t\timage_size=(Params.IMAGE_HEIGHT, Params.IMAGE_WIDTH),\n",
    "\t\tcolor_mode=_color_mode(),\n",
    "\t\tbatch_size=Params.BATCH_SIZE)\n",
    "\t\t\n",
    "\treturn ds\n",
    "\n",
    "def _test_from_dir(path):\n",
    "\tds = image_dataset_from_directory(path,\n",
    "\t\tseed=Params.SEED,\n",
    "\t\tshuffle=True,\n",
    "\t\timage_size=(Params.IMAGE_HEIGHT, Params.IMAGE_WIDTH),\n",
    "\t\tcolor_mode=_color_mode())\n",
    "\n",
    "\treturn ds\n",
    "\n",
    "def load_data(path):\n",
    "\t'''\n",
    "\t\tSummary: Helper to load our data into 3 dataset, train, validation and test\n",
    "\t\t\t\tthe validation is part of train folder splited by VALIDATION_SPLIT factor variable\n",
    "\n",
    "\t\tArguments: Accept a path for main directory of a specific dataset (must have 'train' and 'test' sub-directories)\n",
    "\n",
    "\t\tRetruns: Tuple (train_ds, validation_ds, test_ds)\n",
    "\t'''\n",
    "\n",
    "\ttest_path = f'{path}/test'\n",
    "\ttrain_path = f'{path}/train'\n",
    "\ttrain = _train_from_dir(train_path, 'training')\n",
    "\tvalidation = _train_from_dir(train_path, 'validation')\n",
    "\ttest = _test_from_dir(test_path)\n",
    "\n",
    "\treturn (train, validation, test)\n",
    "\n",
    "def _images_per_emotions(main_dir):\n",
    "\t'''\n",
    "\t\tSummary: Return an array of number of images per emotion (keep the same order as emotion array)\n",
    "\t\tArguments: The main directory (should have train and test directory)\n",
    "\t\tReturn: Array as described above\n",
    "\t'''\n",
    "\n",
    "\tlabels = []\n",
    "\n",
    "\tpath_dir = pathlib.Path(main_dir)\n",
    "\t_debug(f'Directory name is {path_dir.name }')\n",
    "\t_debug(f'list of sub-directories: {os.listdir(main_dir)}')\n",
    "\n",
    "\tdirs = [e for e in path_dir.iterdir() if e.is_dir() and e.name == 'train' ]\n",
    "\tif not len(dirs) > 0: print('Directory given is empty...')\n",
    "\n",
    "\temotions_dir = [e for e in dirs[0].iterdir() if e.is_dir()]\n",
    "\tfor emotion in emotions_dir:\n",
    "\t\t#_debug(f'emotion: {emotion.name}')\n",
    "\t\tcount = len([name for name in os.listdir(emotion) if os.path.isfile(os.path.join(emotion, name))])\n",
    "\t\tlabels.append(count)\n",
    "\n",
    "\t\n",
    "\t_debug(f'labels_count from emotions {len(labels)}')\n",
    "\treturn labels\n",
    "\n",
    "def get_updated_class_weights(path):\n",
    "\tlabels_count = _images_per_emotions(path)\n",
    "\t_debug(f'labels_count {labels_count}')\n",
    "\n",
    "\tlabels_sum = np.sum(labels_count)\n",
    "\t_debug(f'labels sum {labels_sum}')\n",
    "\n",
    "\tlabels_count = labels_count/labels_sum\n",
    "\t_debug(f'updated labels_count {labels_count}')\n",
    "\n",
    "\tclasses_weights = dict(enumerate(labels_count))\n",
    "\t_debug(classes_weights)\n",
    "\treturn classes_weights\n",
    "\n",
    "def display_dataset_infos(train_dataset, test_dataset):\n",
    "\tprint(\"Number of training examples =\", train_dataset.cardinality().numpy())\n",
    "\tprint(\"Number of testing examples =\",  test_dataset.cardinality().numpy())\n",
    "\tprint(\"Number of classes =\", len(train_dataset.class_names))\n",
    "\tprint(\"Classes names =\", train_dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set a basic model params class to hold some helpful params for the neural networks we will create latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParams():\n",
    "\tdef __init__(self, optimiser, loss, metrics):\n",
    "\t\tself.optimiser = optimiser\n",
    "\t\tself.loss = loss\n",
    "\t\tself.metrics = metrics\n",
    "\n",
    "\tdef set_optimiser(optimiser):\n",
    "\t\tself.optimiser = optimiser\n",
    "\n",
    "\tdef set_loss(loss):\n",
    "\t\tself.loss = loss\n",
    "\t\n",
    "\tdef set_metrics(metrics):\n",
    "\t\tself.metrics = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, TensorBoard, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# will decrease learning rate exponentialy after 10 epochs\n",
    "def _scheduler(epoch, lr):\n",
    "\treturn lr if epoch < 10 else lr * tf.math.exp(-.1)\n",
    "\n",
    "\n",
    "def _callbacks():\n",
    "\tlog_dir = os.path.join('./', 'logs') \n",
    "\n",
    "\tearly_stopping = EarlyStopping(mode='min', min_delta=1e-4, patience=Params.PATIENCE, verbose=1, monitor='val_loss', restore_best_weights=True)\n",
    "\tcsv_logger = CSVLogger('model_training.log', separator=\",\", append=False)\n",
    "\ttensor_board = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=False,write_steps_per_second=True,update_freq='batch',profile_batch=10,embeddings_freq=0,embeddings_metadata=None)\n",
    "\tlearning_rate_scheduler = LearningRateScheduler(schedule=_scheduler)\n",
    "\t# you may add more callbacks here, make sure you add it to the returned array\n",
    "\n",
    "\treturn [early_stopping, csv_logger, tensor_board, learning_rate_scheduler]\n",
    "\n",
    "def _optimiser():\n",
    "\t# you may want to modify those values\n",
    "\t#opt = SGD(learning_rate= 1e-3, decay= 1e-4, momentum=.9)\n",
    "\topt = Adam(learning_rate=1e-4, decay= 1e-3)\n",
    "\n",
    "\treturn opt\n",
    "\n",
    "def _loss():\n",
    "\t# you may want to change the loss function\n",
    "\tloss = SparseCategoricalCrossentropy(from_logits=True)\n",
    "\t\n",
    "\treturn loss\n",
    "\n",
    "def _metrics():\n",
    "\t# add metrics you want below\n",
    "\treturn ['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to load our data, we'll first start with data without any modification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_train_ds, ck_validation_ds, ck_test_ds = load_data(CK48_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dataset_infos(ck_train_ds, ck_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display some visualization of our dataset before training our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(ck_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(ck_test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the range values of our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_values_range(ck_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that all values are in range of (0, 255)\n",
    "according to research Neural network are more efficient with scaled images, hence we'll scaled images to (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rescaled_image(ck_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the distribution of the dataset, based on one batch only but it should give us a good approcimation of the real dataset distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_chart(ck_train_ds, ck_validation_ds, 'CK+48')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see one dataset is really unbalanced, despite the fact that we are looking at one batch only\n",
    "we can see that 'surprise' class has way more items that 'neutral' class\n",
    "\n",
    "To deal with it we will adjust the weights for every class\n",
    "\n",
    "Applying this extra step for a balanced dataset should not be bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_class_weight = get_updated_class_weights(CK48_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First attempt\n",
    "\n",
    "Here we will start with a really basic neural network to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPool2D, Dropout, Dense, Flatten, Conv2D\n",
    "\n",
    "# filters is the numbers of filters used to extract facial components like edges, nose eyes and so on\n",
    "# density is for the last layer wich is a fully connected layer\n",
    "\n",
    "def build_basic_model(opt: ModelParams, filters, density):\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(Conv2D(filters, 3, activation='relu',use_bias='True'))\n",
    "\tmodel.add(MaxPool2D(4))\n",
    "\tmodel.add(Dropout(Params.DROPOUT_RATE))\n",
    "\t\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(density, activation='relu'))\n",
    "\tmodel.add(Dense(Params.NUM_CLASSES, activation='softmax', name=\"pred\"))\n",
    "\t\n",
    "\t# Compile\n",
    "\tmodel.compile(optimizer=opt.optimiser, loss=opt.loss, metrics=opt.metrics)\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give our basic model some hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets start with SGD optimiser\n",
    "sgd = SGD(learning_rate= 1e-3, decay= 1e-4, momentum=.9)\n",
    "\n",
    "model = ModelParams(sgd, _loss(), _metrics())\n",
    "\n",
    "# lets start with 128 filters\n",
    "filters = 128 \n",
    "\n",
    "# density will be same as filters for now\n",
    "density = 128\n",
    "\n",
    "cknet = build_basic_model(model, filters, density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have compile our basic neural network, lets see what inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_shape = (Params.BATCH_SIZE,) + Params.SHAPE\n",
    "cknet.build(batch_shape)\n",
    "\n",
    "cknet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to train our model with some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cknet_hist = cknet.fit(ck_train_ds, class_weight=ck_class_weight, callbacks= _callbacks(), verbose = 1,\n",
    "\tshuffle = True, validation_data = ck_validation_ds, batch_size = Params.BATCH_SIZE, epochs = Params.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our basic neural network is trained, let's see it's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(cknet_hist, \"CK+48\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A strange thing just happend, the validation accuracy is better than the training accuracy,\n",
    "we can try to predict on our test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_predictions = cknet.predict(ck_test_ds,verbose = 1,batch_size = Params.BATCH_SIZE)\n",
    "ck_class_index = np.argmax(ck_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we used our neural netwok on test dataset its time to show the results,\n",
    "\n",
    "A confusion matrix seems to be a good idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_for_test_dataset(ck_test_ds, ck_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "save_model(cknet, 'ck_model_v1.h5', include_optimizer=True)\n",
    "np.save('ck_model_v1.weights.h5', cknet.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that our model performs really bad, lets try to fix that.\n",
    "\n",
    "#### Second attempt\n",
    "To overcome the poor performance of our precedent model we'll use a more complex CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def build_model(opt: ModelParams):\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(Conv2D(512, 3,name='conv2d_1', activation='relu',use_bias='True',kernel_regularizer=L2(1e-3), bias_regularizer=L2(1e-4)))\n",
    "\tmodel.add(MaxPool2D(3))\n",
    "\tmodel.add(Dropout(Params.DROPOUT_RATE)) # to prevent overfitting\n",
    "\t\n",
    "\tmodel.add(Conv2D(256, 3,name='conv2d_2', activation='relu',use_bias='True'))\n",
    "\tmodel.add(MaxPool2D(3))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\n",
    "\tmodel.add(Conv2D(128, 3,name='conv2d_3', activation='relu', padding='same', use_bias='True', kernel_regularizer=L2(1e-3), bias_regularizer=L2(1e-4)))\n",
    "\tmodel.add(MaxPool2D(3))\n",
    "\tmodel.add(Dropout(Params.DROPOUT_RATE))\n",
    "\t\n",
    "\t\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(Params.NUM_CLASSES, activation='softmax', name=\"pred\"))\n",
    "\t\n",
    "\tmodel.compile(optimizer=opt.optimiser, loss= opt.loss, metrics=opt.metrics)\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build the more complex model, hopping that it will give us better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelParams(_optimiser(), _loss(), _metrics())\n",
    "cknet = build_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what inside our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cknet.build(batch_shape)\n",
    "\n",
    "cknet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets give our updated model a try, you can feel the excitement!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cknet_hist = cknet.fit(ck_train_ds, class_weight=ck_class_weight, callbacks= _callbacks(), verbose = 1,\n",
    "\tshuffle = True, validation_data = ck_validation_ds, batch_size = Params.BATCH_SIZE, epochs = Params.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At every attempt we'll save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(cknet, 'ck_model_v2.h5', include_optimizer=True)\n",
    "np.save('ck_model_v2.weights.h5', cknet.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deception, it seems that also this neural network didnt perform well\n",
    "<br/>\n",
    "Lets check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(cknet_hist, \"CK+48\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the model on ck+48 test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_evaluation = cknet.evaluate(ck_test_ds, verbose =1)\n",
    "ck_loss, ck_accr = ck_evaluation\n",
    "\n",
    "print(\"ck_validation loss = {:.2f}% , ck_validation accuracy = {:.2f}%\".format(ck_loss*100, ck_accr*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can clearly see that the accuracy is still too low even if the loss is decreasing\n",
    "it mights be connected to the fact that our dataset is too small\n",
    "<br>\n",
    "\n",
    "Lets this conclusion by plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_predictions = cknet.predict(ck_test_ds, verbose = 1)\n",
    "ck_class_index = np.argmax(ck_predictions, axis=1)\n",
    "\n",
    "plot_confusion_matrix_for_test_dataset(ck_test_ds, ck_class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saying that we can continue our journey with some data augmentation, we'll keep this model but we will give our model more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import RandomContrast, RandomRotation, RandomFlip, RandomZoom\n",
    "\n",
    "def images_augmentation_layers(shape):\n",
    "\tlayers = [\n",
    "\t\tRandomFlip(seed=Params.SEED, input_shape=shape),\n",
    "\t\tRandomRotation(Params.ROTATION_FACTOR, fill_mode='constant', interpolation='bilinear', seed=Params.SEED, fill_value=.3),\n",
    "\t\tRandomZoom(Params.ZOOM_FACTOR, .2, fill_mode='reflect', interpolation='nearest', seed=Params.SEED),\n",
    "\t\tRandomContrast(factor=(.2, .6), seed=Params.SEED),\n",
    "\t]\n",
    "\n",
    "\treturn layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = images_augmentation_layers(Params.SHAPE)\n",
    "data_augmentation = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "def plot_augmented_images(dataset):\n",
    "\tfor images, _ in dataset.take(1):\n",
    "\t\tplt.figure(figsize=Params.FIG_SIZE)\n",
    "\t\toriginal = images[0]\n",
    "\t\tplt.subplot(3, 3, 9)\n",
    "\t\tfor i in range(9):\n",
    "\t\t\tplt.subplot(3, 3, i + 1)\n",
    "\t\t\taugmented_images = data_augmentation(tf.expand_dims(original, 0), training=True)\n",
    "\t\t\taugmented_image = augmented_images[0]\n",
    "\t\t\taugmented_image = augmented_image.numpy()\n",
    "\t\t\tplt.imshow(augmented_image.astype('int32'))\n",
    "\t\t\tplt.axis(\"off\")\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_augmented_images(ck_train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third attempt\n",
    "\n",
    "we can now use data augmentation to add more data to our dataset (augmented data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_augmentation_layers(opt: ModelParams):\n",
    "\tmodel = Sequential(layers)\n",
    "\n",
    "\tmodel.add(Conv2D(512, 3,name='conv2d_1', activation='relu',use_bias='True',kernel_regularizer=L2(1e-3), bias_regularizer=L2(1e-4)))\n",
    "\tmodel.add(MaxPool2D(3))\n",
    "\t# to avoid overfitting\n",
    "\tmodel.add(Dropout(Params.DROPOUT_RATE))\n",
    "\t\n",
    "\tmodel.add(Conv2D(256, 3,name='conv2d_2', activation='relu',use_bias='True'))\n",
    "\tmodel.add(MaxPool2D(3))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\n",
    "\tmodel.add(Conv2D(128, 3,name='conv2d_3', activation='relu', padding='same', use_bias='True', kernel_regularizer=L2(1e-3), bias_regularizer=L2(1e-4)))\n",
    "\tmodel.add(MaxPool2D(3))\n",
    "\tmodel.add(Dropout(Params.DROPOUT_RATE))\n",
    "\t\n",
    "\t\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(Params.NUM_CLASSES, activation='softmax', name=\"pred\"))\n",
    "\t\n",
    "\t# Compile\n",
    "\tmodel.compile(optimizer=opt.optimiser, loss= opt.loss, metrics=opt.metrics)\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we dont want to change our base model params so we passing model varaible\n",
    "cknet = build_model_with_augmentation_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cknet.build(batch_shape)\n",
    "\n",
    "cknet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our new model has image augmentation layers\n",
    "\n",
    "Its time to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cknet_hist = cknet.fit(ck_train_ds, class_weight=ck_class_weight, callbacks= _callbacks(), verbose = 1,\n",
    "\tshuffle = True, validation_data = ck_validation_ds, batch_size = Params.BATCH_SIZE, epochs = Params.EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process just end but it also seems to perform badly, lets confirm that thougth by plotting loss and accuracy then we will display the confusion matrix to visualize the predictions of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(cknet_hist, \"CK+48\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we check the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_evaluation = cknet.evaluate(ck_test_ds, verbose =1)\n",
    "ck_loss, ck_accr = ck_evaluation\n",
    "print(\"ck_validation loss = {:.2f}% , ck_validation accuracy = {:.2f}%\".format(ck_loss*100, ck_accr*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then display the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_predictions = cknet.predict(ck_test_ds, verbose = 1)\n",
    "ck_class_index = np.argmax(ck_predictions, axis=1)\n",
    "\n",
    "plot_confusion_matrix_for_test_dataset(ck_test_ds, ck_class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly we didnt get good reslut as expected.\n",
    "\n",
    "Here are few possibles reasons:\n",
    "\n",
    "* We don't have enough data, CK+48 dataset is not a big one\n",
    "* Our model hyper-parameters are not optimal (we can change the learning rate as exemple)\n",
    "* we dont have enough dropout layers\n",
    "* Our network architecture is not complex enough\n",
    "* We didnt give enough time to train\n",
    "\n",
    "In this notbook (future work) we will try all of those approachs\n",
    "\n",
    "To overcome those possible issues we will use those solutions (in order):\n",
    "\n",
    "* To overcome the first possible issue (not enough data) we will try to merge few datasets (CK+48 and FER13)\n",
    "* Based on previous research we will change the hyper-parameters\n",
    "* Simply add fews\n",
    "* Transfer learning might be a nice solution (based on trained model like Resnet50 and so on)\n",
    "* Increasing EPOCH variable might help (we have set early stopping so it wont be a time wasting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9bfb27f93cfb943595e86aecfa227a3cf10f451275b4aa34225ed0aa6ded85d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
